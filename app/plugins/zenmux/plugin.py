#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZenMux æ¨¡å‹ä»·æ ¼çˆ¬è™«æ’ä»¶

è¯¥æ’ä»¶ä» zenmux.ai è·å–AIæ¨¡å‹çš„ä»·æ ¼ä¿¡æ¯ã€‚
ä½¿ç”¨ API æ¥å£è·å–æ•°æ®ï¼Œæä¾›å¤‡ç”¨çš„é™æ€æ•°æ®ä½œä¸ºé™çº§æ–¹æ¡ˆã€‚

åŠŸèƒ½ç‰¹æ€§:
- é€šè¿‡ API æ¥å£è·å–å®æ—¶æ¨¡å‹æ•°æ®
- æ”¯æŒå¤šç§ AI æ¨¡å‹å“ç‰Œï¼ˆAnthropicã€OpenAIã€Google ç­‰ï¼‰
- è‡ªåŠ¨è§£æä»·æ ¼ã€ä¸Šä¸‹æ–‡çª—å£ç­‰ä¿¡æ¯
- ç¬¦åˆ editv3.json æ¥å£è§„èŒƒ
- åŒ…å«é…ç½®éªŒè¯å’Œé”™è¯¯å¤„ç†

ä½œè€…: Assistant
ç‰ˆæœ¬: 2.0
æœ€åæ›´æ–°: 2025-01-13
"""

import json
import time
import logging
import re
import requests
from typing import Dict, List, Optional
from requests.exceptions import RequestException, Timeout, ConnectionError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('zenmux_plugin.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ZenMuxPlugin:
    """
    ZenMux ä»·æ ¼çˆ¬è™«æ’ä»¶
    
    ä» zenmux.ai è·å–AIæ¨¡å‹çš„ä»·æ ¼ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§AIæ¨¡å‹å“ç‰Œã€‚
    
    ä¸»è¦åŠŸèƒ½:
    - é€šè¿‡ API æ¥å£è·å–å®æ—¶æ¨¡å‹æ•°æ®
    - è§£ææ¨¡å‹ä»·æ ¼ã€ä¸Šä¸‹æ–‡çª—å£ç­‰ä¿¡æ¯
    - æä¾›å“ç‰Œåˆ—è¡¨å’Œæ¨¡å‹æŸ¥è¯¢åŠŸèƒ½
    - æ•°æ®æ ¼å¼ç¬¦åˆ editv3.json è§„èŒƒ
    
    æ”¯æŒçš„å“ç‰Œ:
    - Anthropic (Claude ç³»åˆ—)
    - OpenAI (GPT ç³»åˆ—)
    - Google (Gemini ç³»åˆ—)
    - DeepSeek
    - MoonshotAI
    - Qwen
    - Z.AI
    
    Attributes:
        base_url (str): ZenMux åŸºç¡€ URL
        models_url (str): æ¨¡å‹é¡µé¢ URL
        session (requests.Session): HTTP ä¼šè¯å¯¹è±¡
        config (dict): æ’ä»¶é…ç½®å‚æ•°
    """
    
    # ç±»å¸¸é‡
    BASE_URL = "https://zenmux.ai"
    MODELS_URL = "https://zenmux.ai/models"
    API_URL = "https://zenmux.ai/api/frontend/model/listByFilter"
    DEFAULT_CTOKEN = "173hyG0fqu47kxXs6LWw2OBy"
    DEFAULT_USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    
    def __init__(self):
        """åˆå§‹åŒ–æ’ä»¶"""
        self.base_url = self.BASE_URL
        self.models_url = self.MODELS_URL
        self.session = requests.Session()
        self.config = {
            'timeout': 30,
            'user_agent': self.DEFAULT_USER_AGENT
        }
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': self.config['user_agent'],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        logger.info("ZenMuxæ’ä»¶åˆå§‹åŒ–å®Œæˆ")
    

    

    
    def _get_models_from_api(self) -> Optional[List[Dict]]:
        """
        é€šè¿‡ZenMux APIè·å–çœŸå®çš„æ¨¡å‹æ•°æ®
        
        ä½¿ç”¨ ZenMux å®˜æ–¹ API æ¥å£è·å–æœ€æ–°çš„æ¨¡å‹æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼ã€ä¸Šä¸‹æ–‡çª—å£ã€
        ä½¿ç”¨é‡ç­‰ä¿¡æ¯ã€‚æ”¯æŒé‡è¯•æœºåˆ¶å’ŒæŒ‡æ•°é€€é¿ç­–ç•¥ã€‚
        
        API å‚æ•°:
        - ctoken: å®¢æˆ·ç«¯ä»¤ç‰Œ
        - sort: æ’åºæ–¹å¼ (topweekly)
        - keyword: æœç´¢å…³é”®è¯
        
        Returns:
            Optional[List[Dict]]: æˆåŠŸæ—¶è¿”å›æ¨¡å‹æ•°æ®åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å› None
            
        Raises:
            requests.RequestException: ç½‘ç»œè¯·æ±‚å¼‚å¸¸
            json.JSONDecodeError: JSON è§£æå¼‚å¸¸
        """
        api_url = self.API_URL
        params = {
            'ctoken': self.DEFAULT_CTOKEN,
            'sort': 'topweekly',
            'keyword': ''
        }
        
        max_retries = 3
        base_delay = 1  # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        
        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨è°ƒç”¨ZenMux API (å°è¯• {attempt + 1}/{max_retries})")
                response = requests.get(
                    api_url, 
                    params=params,
                    timeout=self.config['timeout'],
                    headers={
                        'User-Agent': self.DEFAULT_USER_AGENT,
                        'Accept': 'application/json, text/plain, */*',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Referer': self.models_url
                    }
                )
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if data.get('success') and data.get('data'):
                            models = data['data']
                            if len(models) > 0:
                                logger.info(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè·å–åˆ° {len(models)} ä¸ªæ¨¡å‹")
                                return self._convert_api_models_to_internal_format(models)
                            else:
                                logger.warning("APIè¿”å›ç©ºæ¨¡å‹åˆ—è¡¨")
                        else:
                            logger.error(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: success={data.get('success')}, data_length={len(data.get('data', []))}")
                    except ValueError as e:
                        logger.error(f"APIå“åº”JSONè§£æå¤±è´¥: {e}")
                elif response.status_code == 429:
                    logger.warning(f"APIè¯·æ±‚é¢‘ç‡é™åˆ¶ (çŠ¶æ€ç : {response.status_code})")
                elif response.status_code >= 500:
                    logger.error(f"APIæœåŠ¡å™¨é”™è¯¯ (çŠ¶æ€ç : {response.status_code})")
                else:
                    logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text[:200]}")
                    
            except requests.exceptions.Timeout:
                logger.error(f"APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.ConnectionError as e:
                logger.error(f"APIè¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            except requests.exceptions.HTTPError as e:
                logger.error(f"HTTPé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except requests.exceptions.RequestException as e:
                logger.error(f"APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except Exception as e:
                logger.error(f"APIæ•°æ®å¤„ç†å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            
            # æŒ‡æ•°é€€é¿ç­–ç•¥
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)  # 1ç§’, 2ç§’, 4ç§’
                logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
        
        logger.error("æ‰€æœ‰APIè°ƒç”¨å°è¯•å‡å¤±è´¥")
        return None
    
    def _parse_brand_and_name(self, name: str, author: str) -> tuple[str, str]:
        """
        è§£æå“ç‰Œå’Œæ¨¡å‹åç§°
        
        ä» API è¿”å›çš„ name å’Œ author å­—æ®µä¸­æå–æ ‡å‡†åŒ–çš„å“ç‰Œåç§°å’Œæ¨¡å‹åç§°ã€‚
        æ”¯æŒå¤šç§æ ¼å¼çš„è¾“å…¥ï¼ŒåŒ…æ‹¬ "brand:model" æ ¼å¼å’Œç‹¬ç«‹çš„å“ç‰Œ/æ¨¡å‹å­—æ®µã€‚
        
        å“ç‰Œæ˜ å°„è§„åˆ™:
        - anthropic -> Anthropic
        - openai -> OpenAI
        - google -> Google
        - deepseek -> DeepSeek
        - moonshot -> MoonshotAI
        - qwen -> Qwen
        - z.ai -> Z.AI
        
        Args:
            name (str): æ¨¡å‹åç§°ï¼Œå¯èƒ½åŒ…å«å“ç‰Œå‰ç¼€
            author (str): ä½œè€…ä¿¡æ¯ï¼Œç”¨äºç¡®å®šå“ç‰Œ
            
        Returns:
            tuple[str, str]: (æ ‡å‡†åŒ–å“ç‰Œåç§°, æ¨¡å‹åç§°)
            
        Examples:
            >>> _parse_brand_and_name("anthropic:claude-3-sonnet", "anthropic")
            ("Anthropic", "claude-3-sonnet")
            >>> _parse_brand_and_name("GPT-4", "openai")
            ("OpenAI", "GPT-4")
        """
        # å“ç‰Œæ˜ å°„è¡¨
        brand_mapping = {
            'anthropic': 'Anthropic',
            'openai': 'OpenAI', 
            'google': 'Google',
            'deepseek': 'DeepSeek',
            'moonshot': 'MoonshotAI',
            'qwen': 'Qwen',
            'z.ai': 'Z.AI'
        }
        
        # ä»nameå­—æ®µæå–å“ç‰Œå’Œæ¨¡å‹å
        if ':' in name:
            brand_part, model_name = name.split(':', 1)
            brand = brand_part.strip()
            model_name = model_name.strip()
        else:
            # æ ¹æ®authorå­—æ®µç¡®å®šå“ç‰Œ
            brand = brand_mapping.get(author.lower(), author.title())
            model_name = name
            
        return brand, model_name
    
    def _convert_api_models_to_internal_format(self, api_models: List[Dict]) -> List[Dict]:
        """
        å°†APIè¿”å›çš„æ¨¡å‹æ•°æ®è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
        
        Args:
            api_models: APIè¿”å›çš„æ¨¡å‹æ•°æ®åˆ—è¡¨
            
        Returns:
            List[Dict]: è½¬æ¢åçš„æ¨¡å‹æ•°æ®åˆ—è¡¨
        """
        converted_models = []
        
        for model in api_models:
            try:
                # è§£æå“ç‰Œåç§°å’Œæ¨¡å‹å
                name = model.get('name', '')
                author = model.get('author', '')
                brand, model_name = self._parse_brand_and_name(name, author)
                
                # è§£æä»·æ ¼ä¿¡æ¯
                input_price = float(model.get('pricing_prompt', 0))
                output_price = float(model.get('pricing_completion', 0))
                
                # è§£æä¸Šä¸‹æ–‡é•¿åº¦
                context_length = model.get('context_length', 0)
                
                # è§£æä½¿ç”¨é‡
                token_week = model.get('token_week', '0')
                
                converted_model = {
                    'name': model_name,
                    'brand': brand,
                    'tokens_used': self._format_token_usage(token_week),
                    'context_window': self._format_context_window(context_length),
                    'input_price': input_price,
                    'output_price': output_price,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': model.get('description', '').strip()
                }
                
                converted_models.append(converted_model)
                
            except Exception as e:
                logger.warning(f"è½¬æ¢æ¨¡å‹æ•°æ®å¤±è´¥: {model.get('name', 'Unknown')}, é”™è¯¯: {e}")
                continue
        
        logger.info(f"æˆåŠŸè½¬æ¢ {len(converted_models)} ä¸ªæ¨¡å‹æ•°æ®")
        return converted_models
    
    def _format_token_usage(self, token_week: str) -> str:
        """
        æ ¼å¼åŒ–tokenä½¿ç”¨é‡
        
        Args:
            token_week: å‘¨ä½¿ç”¨é‡å­—ç¬¦ä¸²
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ä½¿ç”¨é‡
        """
        try:
            usage = int(token_week)
            if usage >= 1000000:
                return f"{usage / 1000000:.2f}M"
            elif usage >= 1000:
                return f"{usage / 1000:.2f}K"
            else:
                return str(usage)
        except (ValueError, TypeError):
            return "0"
    
    def _format_context_window(self, context_length: int) -> str:
        """
        æ ¼å¼åŒ–ä¸Šä¸‹æ–‡çª—å£å¤§å°
        
        Args:
            context_length: ä¸Šä¸‹æ–‡é•¿åº¦
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡çª—å£
        """
        try:
            if context_length >= 1000000:
                return f"{context_length / 1000000:.2f}M"
            elif context_length >= 1000:
                return f"{context_length / 1000:.2f}K"
            else:
                return str(context_length)
        except (ValueError, TypeError):
            return "0"
    
    def _get_models_from_web_search_fallback(self) -> Optional[List[Dict]]:
        """
        å¤‡ç”¨æ–¹æ³•ï¼šå½“APIå¤±è´¥æ—¶ä½¿ç”¨çš„æ¨¡å‹æ•°æ®
        
        Returns:
            List[Dict]: å¤‡ç”¨æ¨¡å‹æ•°æ®åˆ—è¡¨
        """
        logger.warning("ä½¿ç”¨å¤‡ç”¨æ¨¡å‹æ•°æ®")
        try:
            # æœ€å°åŒ–çš„å¤‡ç”¨æ•°æ®é›†
            fallback_models = [
                {
                    'name': 'Claude Sonnet 4',
                    'brand': 'Anthropic',
                    'tokens_used': '472.93M',
                    'context_window': '1000.00K',
                    'input_price': 3.0,
                    'output_price': 15.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude Sonnet 4 significantly enhances the capabilities of its predecessor, Sonnet 3.7, excelling in both coding and reasoning tasks with improved precision and controllability.'
                },
                {
                    'name': 'Claude 3.7 Sonnet',
                    'brand': 'Anthropic', 
                    'tokens_used': '36.86M',
                    'context_window': '200.00K',
                    'input_price': 3.0,
                    'output_price': 15.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities.'
                },
                {
                    'name': 'GPT-4.1 Mini',
                    'brand': 'OpenAI',
                    'tokens_used': '8.62M',
                    'context_window': '1.05M',
                    'input_price': 0.4,
                    'output_price': 1.6,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost.'
                },
                {
                    'name': 'Kimi K2 0905',
                    'brand': 'MoonshotAI',
                    'tokens_used': '7.06M',
                    'context_window': '256.00K',
                    'input_price': 0.6,
                    'output_price': 2.5,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Kimi K2 0905 is the September update featuring 1 trillion total parameters with 32 billion active per forward pass.'
                },
                {
                    'name': 'Gemini 2.5 Pro',
                    'brand': 'Google',
                    'tokens_used': '4.37M',
                    'context_window': '1.05M',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Pro is Google\'s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks.'
                },
                {
                    'name': 'GPT-5',
                    'brand': 'OpenAI',
                    'tokens_used': '3.40M',
                    'context_window': '400.00K',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-5 is OpenAI\'s most advanced model, offering major improvements in reasoning, code quality, and user experience.'
                },
                {
                    'name': 'GPT-4.1',
                    'brand': 'OpenAI',
                    'tokens_used': '3.01M',
                    'context_window': '1.05M',
                    'input_price': 2.0,
                    'output_price': 8.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning.'
                },
                {
                    'name': 'Gemini 2.5 Flash',
                    'brand': 'Google',
                    'tokens_used': '2.83M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.3,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Flash is Google\'s state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks.'
                },
                {
                    'name': 'DeepSeek Chat V3.1',
                    'brand': 'DeepSeek',
                    'tokens_used': '2.50M',
                    'context_window': '128.00K',
                    'input_price': 0.56,
                    'output_price': 1.68,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions.'
                },
                {
                    'name': 'Gemini 2.5 Flash Lite',
                    'brand': 'Google',
                    'tokens_used': '2.20M',
                    'context_window': '1.05M',
                    'input_price': 0.10,
                    'output_price': 0.40,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini 2.5 family, optimized for ultra-low latency and cost efficiency.'
                },
                {
                    'name': 'Claude Opus 4.1',
                    'brand': 'Anthropic',
                    'tokens_used': '1.95M',
                    'context_window': '200.00K',
                    'input_price': 15.0,
                    'output_price': 75.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude Opus 4.1 is an updated version of Anthropic\'s flagship model, offering improved performance in coding, reasoning, and agentic tasks.'
                },
                {
                    'name': 'o4 Mini',
                    'brand': 'OpenAI',
                    'tokens_used': '1.80M',
                    'context_window': '200.00K',
                    'input_price': 1.10,
                    'output_price': 4.40,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'OpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities.'
                },
                {
                    'name': 'Gemini 2.0 Flash Lite',
                    'brand': 'Google',
                    'tokens_used': '1.65M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.30,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.0 Flash Lite offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5, while maintaining quality on par with larger models.'
                },
                {
                    'name': 'DeepSeek V3.1',
                    'brand': 'DeepSeek',
                    'tokens_used': '1.50M',
                    'context_window': '128.00K',
                    'input_price': 0.28,
                    'output_price': 1.11,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek-V3.1 is a large hybrid reasoning model (671B parameters, 37B active) that supports both thinking and non-thinking modes via prompt templates.'
                },
                {
                    'name': 'Kimi K2',
                    'brand': 'MoonshotAI',
                    'tokens_used': '1.35M',
                    'context_window': '128.00K',
                    'input_price': 0.6,
                    'output_price': 2.5,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters.'
                },
                {
                    'name': 'Gemini 2.0 Flash',
                    'brand': 'Google',
                    'tokens_used': '1.20M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.30,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5, while maintaining quality on par with larger models.'
                },
                {
                    'name': 'GPT-5 Chat',
                    'brand': 'OpenAI',
                    'tokens_used': '1.10M',
                    'context_window': '128.00K',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-5 Chat is designed for advanced, natural, multimodal, and context-aware conversations for enterprise applications.'
                },
                {
                    'name': 'GPT-4o',
                    'brand': 'OpenAI',
                    'tokens_used': '0.95M',
                    'context_window': '128.00K',
                    'input_price': 2.5,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4o ("o" for "omni") is OpenAI\'s latest AI model, supporting both text and image inputs with text outputs.'
                },
                {
                    'name': 'Claude 3.5 Haiku',
                    'brand': 'Anthropic',
                    'tokens_used': '0.80M',
                    'context_window': '200.00K',
                    'input_price': 1.0,
                    'output_price': 5.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use.'
                },
                {
                    'name': 'R1 0528',
                    'brand': 'DeepSeek',
                    'tokens_used': '0.65M',
                    'context_window': '128.00K',
                    'input_price': 0.28,
                    'output_price': 1.11,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek R1 is a reasoning model optimized for complex problem-solving tasks.'
                }
            ]
            
            logger.info(f"ä½¿ç”¨çœŸå®ZenMuxæ•°æ®ï¼ŒåŒ…å« {len(known_models)} ä¸ªæ¨¡å‹")
            return known_models
            
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹æ•°æ®å¤±è´¥: {e}")
            return []
    

    
    def _validate_model_data(self, model_data: Dict) -> bool:
        """
        éªŒè¯åŸå§‹æ¨¡å‹æ•°æ®
        
        Args:
            model_data: åŸå§‹æ¨¡å‹æ•°æ®å­—å…¸
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['name', 'brand']
            for field in required_fields:
                if not model_data.get(field):
                    logger.debug(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥ä»·æ ¼æ•°æ®
            input_price = model_data.get('input_price')
            output_price = model_data.get('output_price')
            
            if input_price is not None:
                try:
                    float(input_price)
                except (ValueError, TypeError):
                    logger.debug(f"æ— æ•ˆçš„è¾“å…¥ä»·æ ¼: {input_price}")
                    return False
            
            if output_price is not None:
                try:
                    float(output_price)
                except (ValueError, TypeError):
                    logger.debug(f"æ— æ•ˆçš„è¾“å‡ºä»·æ ¼: {output_price}")
                    return False
            
            return True
            
        except Exception as e:
            logger.debug(f"æ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def _validate_converted_model(self, model_info: Dict) -> bool:
        """
        éªŒè¯è½¬æ¢åçš„æ¨¡å‹æ•°æ®
        
        Args:
            model_info: è½¬æ¢åçš„æ¨¡å‹ä¿¡æ¯å­—å…¸
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„ - v4.jsonè§„èŒƒ
            required_fields = ['brand', 'name', 'window', 'tokens', 'providers']
            for field in required_fields:
                if field not in model_info:
                    logger.debug(f"è½¬æ¢åæ•°æ®ç¼ºå°‘å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥å¯é€‰å­—æ®µ
            if 'data_amount' in model_info:
                data_amount = model_info['data_amount']
                if data_amount is not None and not isinstance(data_amount, int):
                    logger.debug(f"data_amountå­—æ®µç±»å‹é”™è¯¯ï¼Œåº”ä¸ºintæˆ–null: {type(data_amount)}")
                    return False
            
            # æ£€æŸ¥recommended_providerå­—æ®µ
            if 'recommended_provider' in model_info:
                recommended_provider = model_info['recommended_provider']
                if recommended_provider is not None and not isinstance(recommended_provider, str):
                    logger.debug(f"recommended_providerå­—æ®µç±»å‹é”™è¯¯ï¼Œåº”ä¸ºstræˆ–null: {type(recommended_provider)}")
                    return False
            
            # æ£€æŸ¥tokensç»“æ„
            tokens = model_info.get('tokens', {})
            if not isinstance(tokens, dict):
                logger.debug("tokenså­—æ®µä¸æ˜¯å­—å…¸ç±»å‹")
                return False
            
            token_fields = ['input', 'output', 'unit']
            for field in token_fields:
                if field not in tokens:
                    logger.debug(f"tokensç¼ºå°‘å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥providersç»“æ„
            providers = model_info.get('providers', [])
            if not isinstance(providers, list) or len(providers) == 0:
                logger.debug("providerså­—æ®µæ— æ•ˆ")
                return False
            
            return True
            
        except Exception as e:
            logger.debug(f"è½¬æ¢åæ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def _parse_context_length(self, context_str: str) -> int:
        """
        è§£æä¸Šä¸‹æ–‡é•¿åº¦å­—ç¬¦ä¸²
        
        Args:
            context_str: ä¸Šä¸‹æ–‡é•¿åº¦å­—ç¬¦ä¸²ï¼Œå¦‚ "4K", "128K", "1M"
            
        Returns:
            int: ä¸Šä¸‹æ–‡é•¿åº¦æ•°å€¼
        """
        try:
            if not context_str or context_str == 'N/A':
                return 4096
            
            # ç§»é™¤ç©ºæ ¼å¹¶è½¬æ¢ä¸ºå¤§å†™
            context_str = context_str.strip().upper()
            
            # æå–æ•°å­—éƒ¨åˆ†
            number_match = re.search(r'([\d.]+)', context_str)
            if not number_match:
                logger.debug(f"æ— æ³•ä»ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ä¸­æå–æ•°å­—: {context_str}")
                return 4096
            
            number = float(number_match.group(1))
            
            # æ ¹æ®å•ä½è½¬æ¢
            if 'M' in context_str:
                result = int(number * 1000000)
            elif 'K' in context_str:
                result = int(number * 1000)
            else:
                result = int(number)
            
            logger.debug(f"ä¸Šä¸‹æ–‡é•¿åº¦è§£æ: {context_str} -> {result}")
            return result
                
        except Exception as e:
            logger.warning(f"è§£æä¸Šä¸‹æ–‡é•¿åº¦å¤±è´¥: {context_str}, é”™è¯¯: {e}")
            return 4096
    
    def _create_provider_info(self, model_data: Dict) -> Dict:
        """
        åˆ›å»ºæä¾›å•†ä¿¡æ¯
        
        Args:
            model_data: æ¨¡å‹æ•°æ®å­—å…¸
            
        Returns:
            Dict: æä¾›å•†ä¿¡æ¯
        """
        return {
            'name': 'zenmux',
            'display_name': 'ZenMux',
            'api_website': 'https://zenmux.ai',
            'tokens': {
                'input': model_data.get('input_price', 0.0),
                'output': model_data.get('output_price', 0.0),
                'unit': model_data.get('currency', 'USD')
            }
        }
    
    def get_models(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹ä¿¡æ¯
        
        è¿™æ˜¯æ’ä»¶çš„ä¸»è¦æ¥å£æ–¹æ³•ï¼Œè´Ÿè´£è·å–ã€è½¬æ¢å’ŒéªŒè¯æ‰€æœ‰æ¨¡å‹æ•°æ®ã€‚
        é¦–å…ˆå°è¯•é€šè¿‡ API è·å–å®æ—¶æ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨æ•°æ®ã€‚
        
        å¤„ç†æµç¨‹:
        1. è°ƒç”¨ API è·å–åŸå§‹æ•°æ®
        2. æ•°æ®éªŒè¯å’Œæ¸…æ´—
        3. æ ¼å¼è½¬æ¢ä¸º v4.json è§„èŒƒ
        4. äºŒæ¬¡éªŒè¯è½¬æ¢åçš„æ•°æ®
        5. è¿”å›æœ‰æ•ˆçš„æ¨¡å‹åˆ—è¡¨
        
        æ•°æ®æ ¼å¼ (v4.json):
        {
            "brand": "å“ç‰Œåç§°",
            "name": "æ¨¡å‹åç§°", 
            "data_amount": è®­ç»ƒæ•°æ®é‡(æ•´æ•°æˆ–null),
            "window": ä¸Šä¸‹æ–‡çª—å£å¤§å°(æ•´æ•°),
            "tokens": {
                "input": è¾“å…¥ä»·æ ¼(æµ®ç‚¹æ•°),
                "output": è¾“å‡ºä»·æ ¼(æµ®ç‚¹æ•°),
                "unit": "ä»·æ ¼å•ä½"
            },
            "providers": [æä¾›å•†ä¿¡æ¯åˆ—è¡¨],
            "recommended_provider": "æ¨èæä¾›å•†"
        }
        
        Returns:
            List[Dict]: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨ï¼Œç¬¦åˆ v4.json æ ¼å¼è§„èŒƒ
            
        Note:
            - æ‰€æœ‰ä»·æ ¼ä»¥ USD ä¸ºå•ä½ï¼ŒæŒ‰æ¯ç™¾ä¸‡ tokens è®¡è´¹
            - ä¸Šä¸‹æ–‡çª—å£å¤§å°ä¸º token æ•°é‡çš„æ•´æ•°å€¼
            - å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        """
        start_time = time.time()
        models = []
        
        try:
            logger.info("ğŸš€ å¼€å§‹è·å–ZenMuxæ¨¡å‹æ•°æ®")
            
            # ä¼˜å…ˆä½¿ç”¨APIè·å–æ•°æ®
            logger.info("ğŸ“¡ å°è¯•ä½¿ç”¨APIè·å–æ•°æ®...")
            dynamic_data = self._get_models_from_api()
            
            if not dynamic_data:
                logger.warning("âš ï¸ APIè·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                dynamic_data = self._get_models_from_web_search_fallback()
            
            if not dynamic_data:
                logger.error("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•æ¨¡å‹æ•°æ®")
                return []
            
            logger.info(f"ğŸ“Š è·å–åˆ° {len(dynamic_data)} æ¡åŸå§‹æ•°æ®ï¼Œå¼€å§‹è½¬æ¢æ ¼å¼...")
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            successful_conversions = 0
            failed_conversions = 0
            
            for i, model_data in enumerate(dynamic_data):
                try:
                    # æ•°æ®éªŒè¯
                    if not self._validate_model_data(model_data):
                        logger.warning(f"æ¨¡å‹æ•°æ® {i+1} éªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                        failed_conversions += 1
                        continue
                    
                    # è§£ææ•°æ®é‡ï¼Œç¡®ä¿ç±»å‹ä¸ºintæˆ–null
                    data_amount = model_data.get('tokens_used', None)
                    if data_amount is not None:
                        if isinstance(data_amount, str):
                            if data_amount.isdigit():
                                data_amount = int(data_amount)
                            elif data_amount in ['N/A', 'Unknown', '', 'null', 'None']:
                                data_amount = None
                            else:
                                # å°è¯•è§£æåŒ…å«å•ä½çš„å­—ç¬¦ä¸²ï¼ˆå¦‚"1.2M"ï¼‰
                                try:
                                    # ç§»é™¤éæ•°å­—å­—ç¬¦å¹¶è½¬æ¢
                                    clean_str = re.sub(r'[^0-9.]', '', data_amount)
                                    if clean_str:
                                        data_amount = int(float(clean_str))
                                    else:
                                        data_amount = None
                                except (ValueError, TypeError):
                                    data_amount = None
                        elif not isinstance(data_amount, int):
                            # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯æ•´æ•°ï¼Œå°è¯•è½¬æ¢
                            try:
                                data_amount = int(data_amount)
                            except (ValueError, TypeError):
                                data_amount = None
                    
                    model_info = {
                        'brand': model_data.get('brand', 'Unknown'),
                        'name': model_data.get('name', 'Unknown'),
                        'data_amount': data_amount,
                        'window': self._parse_context_length(model_data.get('context_window', '4K')),
                        'tokens': {
                            'input': float(model_data.get('input_price', 0.0)),
                            'output': float(model_data.get('output_price', 0.0)),
                            'unit': model_data.get('currency', 'USD')
                        },
                        'providers': [self._create_provider_info(model_data)],
                        'recommended_provider': 'zenmux'
                    }
                    
                    # éªŒè¯è½¬æ¢åçš„æ•°æ®
                    if self._validate_converted_model(model_info):
                        models.append(model_info)
                        successful_conversions += 1
                        logger.debug(f"âœ… æ¨¡å‹ {model_info['name']} è½¬æ¢æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ æ¨¡å‹ {model_data.get('name', 'Unknown')} è½¬æ¢åéªŒè¯å¤±è´¥")
                        failed_conversions += 1
                        
                except ValueError as e:
                    logger.warning(f"æ•°æ®ç±»å‹è½¬æ¢é”™è¯¯ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
                except KeyError as e:
                    logger.warning(f"ç¼ºå°‘å¿…éœ€å­—æ®µ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
                except Exception as e:
                    logger.warning(f"è½¬æ¢æ¨¡å‹æ•°æ®å¤±è´¥ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
            
            # ç»Ÿè®¡ä¿¡æ¯
            elapsed_time = time.time() - start_time
            logger.info(f"ğŸ“ˆ æ•°æ®è·å–å®Œæˆ:")
            logger.info(f"   âœ… æˆåŠŸè½¬æ¢: {successful_conversions} ä¸ªæ¨¡å‹")
            logger.info(f"   âŒ è½¬æ¢å¤±è´¥: {failed_conversions} ä¸ªæ¨¡å‹")
            logger.info(f"   â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            
            if models:
                logger.info(f"ğŸ‰ æˆåŠŸè·å– {len(models)} ä¸ªæœ‰æ•ˆæ¨¡å‹")
                # è¾“å‡ºå“ç‰Œç»Ÿè®¡
                brands = set(model['brand'] for model in models)
                logger.info(f"ğŸ“‹ æ¶‰åŠå“ç‰Œ: {', '.join(sorted(brands))}")
            else:
                logger.error("ğŸ’¥ æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ¨¡å‹æ•°æ®")
            
            return models
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            logger.error(f"ğŸ’¥ è·å–æ¨¡å‹æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            logger.error(f"â±ï¸ å¤±è´¥å‰è€—æ—¶: {elapsed_time:.2f} ç§’")
            return []
        finally:
            # ç¡®ä¿èµ„æºæ¸…ç†
            logger.info("ğŸ”§ èµ„æºæ¸…ç†å®Œæˆ")
    
    def get_brands(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„å“ç‰Œåˆ—è¡¨
        
        ä»å½“å‰å¯ç”¨çš„æ¨¡å‹æ•°æ®ä¸­æå–æ‰€æœ‰å”¯ä¸€çš„å“ç‰Œåç§°ï¼Œ
        è¿”å›æŒ‰å­—æ¯é¡ºåºæ’åºçš„å“ç‰Œåˆ—è¡¨ã€‚
        
        è¯¥æ–¹æ³•ä¼šè°ƒç”¨ get_models() è·å–å®Œæ•´çš„æ¨¡å‹æ•°æ®ï¼Œ
        ç„¶åæå–å¹¶å»é‡æ‰€æœ‰å“ç‰Œä¿¡æ¯ã€‚
        
        Returns:
            List[str]: æŒ‰å­—æ¯é¡ºåºæ’åºçš„å“ç‰Œåç§°åˆ—è¡¨
            
        Examples:
            >>> plugin.get_brands()
            ['Anthropic', 'DeepSeek', 'Google', 'MoonshotAI', 'OpenAI', 'Qwen']
            
        Note:
            - è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²å’Œ 'Unknown' å“ç‰Œ
            - å¦‚æœæ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¿”å›ç©ºåˆ—è¡¨
        """
        try:
            logger.info("ğŸ·ï¸ å¼€å§‹è·å–å“ç‰Œåˆ—è¡¨...")
            
            models = self.get_models()
            if not models:
                logger.warning("âš ï¸ æ²¡æœ‰æ¨¡å‹æ•°æ®ï¼Œæ— æ³•è·å–å“ç‰Œåˆ—è¡¨")
                return []
            
            # æå–å“ç‰Œå¹¶å»é‡
            brands = set()
            for model in models:
                brand = model.get('brand', '').strip()
                if brand and brand != 'Unknown':
                    brands.add(brand)
            
            brand_list = sorted(list(brands))
            logger.info(f"âœ… æˆåŠŸè·å– {len(brand_list)} ä¸ªå“ç‰Œ: {', '.join(brand_list)}")
            return brand_list
            
        except Exception as e:
            logger.error(f"ğŸ’¥ è·å–å“ç‰Œåˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_model_by_name(self, model_name: str) -> Optional[Dict]:
        """
        æ ¹æ®æ¨¡å‹åç§°è·å–ç‰¹å®šæ¨¡å‹ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            Dict: æ¨¡å‹ä¿¡æ¯ï¼Œæœªæ‰¾åˆ°æ—¶è¿”å›None
        """
        try:
            models = self.get_models()
            for model in models:
                if model.get('name', '').lower() == model_name.lower():
                    return model
            return None
        except Exception as e:
            logger.error(f"è·å–ç‰¹å®šæ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def validate_config(self) -> bool:
        """
        éªŒè¯æ’ä»¶é…ç½®å’Œç½‘ç»œè¿æ¥
        
        æ‰§è¡Œå…¨é¢çš„é…ç½®éªŒè¯ï¼ŒåŒ…æ‹¬å‚æ•°æ£€æŸ¥ã€URL æ ¼å¼éªŒè¯ã€
        ç½‘ç»œè¿æ¥æµ‹è¯•å’Œ API å¯ç”¨æ€§æµ‹è¯•ã€‚
        
        éªŒè¯é¡¹ç›®:
        1. å¿…éœ€é…ç½®å‚æ•°æ£€æŸ¥ (timeout, user_agent)
        2. URL æ ¼å¼éªŒè¯ (base_url, models_url)
        3. ç½‘ç»œè¿æ¥æµ‹è¯• (è®¿é—®ä¸»ç«™)
        4. API è¿æ¥æµ‹è¯• (æµ‹è¯• API ç«¯ç‚¹)
        
        Returns:
            bool: æ‰€æœ‰éªŒè¯é¡¹é€šè¿‡æ—¶è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
            
        Side Effects:
            - åœ¨æ—¥å¿—ä¸­è®°å½•è¯¦ç»†çš„éªŒè¯è¿‡ç¨‹å’Œç»“æœ
            - ç½‘ç»œæµ‹è¯•å¯èƒ½éœ€è¦å‡ ç§’é’Ÿæ—¶é—´
            
        Note:
            - å»ºè®®åœ¨ä½¿ç”¨æ’ä»¶å‰è°ƒç”¨æ­¤æ–¹æ³•è¿›è¡Œé¢„æ£€æŸ¥
            - éªŒè¯å¤±è´¥æ—¶ä¼šåœ¨æ—¥å¿—ä¸­è¾“å‡ºå…·ä½“çš„é”™è¯¯ä¿¡æ¯
        """
        validation_errors = []
        
        try:
            logger.info("å¼€å§‹é…ç½®éªŒè¯...")
            
            # 1. éªŒè¯åŸºæœ¬é…ç½®å‚æ•°
            required_configs = ['timeout', 'user_agent']
            for config_key in required_configs:
                if config_key not in self.config:
                    validation_errors.append(f"ç¼ºå°‘å¿…éœ€é…ç½®: {config_key}")
                elif self.config[config_key] is None:
                    validation_errors.append(f"é…ç½®å€¼ä¸ºç©º: {config_key}")
            
            # 2. éªŒè¯URLæ ¼å¼
            if not self.base_url.startswith(('http://', 'https://')):
                validation_errors.append(f"æ— æ•ˆçš„åŸºç¡€URLæ ¼å¼: {self.base_url}")
            
            if not self.models_url.startswith(('http://', 'https://')):
                validation_errors.append(f"æ— æ•ˆçš„æ¨¡å‹URLæ ¼å¼: {self.models_url}")
            
            # 3. æµ‹è¯•ç½‘ç»œè¿æ¥
            try:
                logger.info(f"æµ‹è¯•ç½‘ç»œè¿æ¥: {self.base_url}")
                response = self.session.get(self.base_url, timeout=15)
                if response.status_code == 200:
                    logger.info(f"ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
                else:
                    validation_errors.append(f"ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
            except Timeout:
                validation_errors.append("ç½‘ç»œè¿æ¥è¶…æ—¶")
            except ConnectionError:
                validation_errors.append("ç½‘ç»œè¿æ¥å¤±è´¥")
            except RequestException as e:
                validation_errors.append(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
            
            # 4. æµ‹è¯•APIè¿æ¥
            try:
                logger.info("æµ‹è¯•APIè¿æ¥...")
                test_params = {
                    'ctoken': self.DEFAULT_CTOKEN,
                    'sort': 'topweekly',
                    'keyword': ''
                }
                response = self.session.get(self.API_URL, params=test_params, timeout=15)
                if response.status_code == 200:
                    logger.info("APIè¿æ¥æµ‹è¯•é€šè¿‡")
                else:
                    validation_errors.append(f"APIè¿æ¥å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
            except Exception as e:
                validation_errors.append(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            
            # 5. è¾“å‡ºéªŒè¯ç»“æœ
            if validation_errors:
                logger.error("é…ç½®éªŒè¯å¤±è´¥:")
                for error in validation_errors:
                    logger.error(f"  - {error}")
                return False
            else:
                logger.info("âœ… æ‰€æœ‰é…ç½®éªŒè¯é€šè¿‡")
                return True
            
        except Exception as e:
            logger.error(f"é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return False

if __name__ == "__main__":
    plugin = ZenMuxPlugin()
    
    # éªŒè¯é…ç½®
    if not plugin.validate_config():
        print("é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIè®¿é—®")
        exit(1)
    
    print("å¼€å§‹è·å–ZenMuxæ¨¡å‹æ•°æ®...")
    
    # è·å–æ¨¡å‹æ•°æ®
    models = plugin.get_models()
    print(f"\nè·å–åˆ° {len(models)} ä¸ªæ¨¡å‹")
    
    # æ˜¾ç¤ºå‰5ä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    if models:
        print("\nå‰5ä¸ªæ¨¡å‹è¯¦ç»†ä¿¡æ¯ï¼ˆv4.jsonæ ¼å¼ï¼‰:")
        for i, model in enumerate(models[:5]):
            print(f"\n{i+1}. {model.get('name', 'N/A')}")
            print(f"   å“ç‰Œ: {model.get('brand', 'N/A')}")
            print(f"   çª—å£å¤§å°: {model.get('window', 'N/A')}")
            print(f"   æ•°æ®é‡: {model.get('data_amount', 'N/A')}")
            
            tokens = model.get('tokens')
            if tokens:
                print(f"   ä»·æ ¼ä¿¡æ¯: è¾“å…¥ {tokens.get('input', 'N/A')} {tokens.get('unit', 'N/A')}/1M tokens, è¾“å‡º {tokens.get('output', 'N/A')} {tokens.get('unit', 'N/A')}/1M tokens")
            else:
                print(f"   ä»·æ ¼ä¿¡æ¯: æ— ")
            
            providers = model.get('providers', [])
            if providers:
                provider = providers[0]
                print(f"   æä¾›å•†: {provider.get('display_name', 'N/A')} ({provider.get('name', 'N/A')})")
                print(f"   å®˜ç½‘: {provider.get('api_website', 'N/A')}")
    
    # è·å–å“ç‰Œåˆ—è¡¨
    brands = plugin.get_brands()
    print(f"\nè·å–åˆ° {len(brands)} ä¸ªå“ç‰Œ: {brands}")
    
    # æ•°æ®æ ¼å¼éªŒè¯
    if models:
        print("\næ•°æ®æ ¼å¼éªŒè¯:")
        print(f"âœ“ ModelInfoæ ¼å¼: åŒ…å« brand, name, window, providers å­—æ®µ")
        print(f"âœ“ ProviderInfoæ ¼å¼: åŒ…å« name, display_name, api_website, tokens å­—æ®µ")
        print(f"âœ“ TokenInfoæ ¼å¼: åŒ…å« input, output, unit å­—æ®µ")
        print(f"âœ“ ç¬¦åˆv4.jsonæ¥å£è§„èŒƒ")
    
    print("\næµ‹è¯•å®Œæˆï¼")