#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZenMux æ¨¡å‹ä»·æ ¼çˆ¬è™«æ’ä»¶

è¯¥æ’ä»¶ä» zenmux.ai è·å–AIæ¨¡å‹çš„ä»·æ ¼ä¿¡æ¯ã€‚
ç»“åˆ requests + beautifulsoup4 å’Œ Puppeteer å¤„ç†åŠ¨æ€å†…å®¹ã€‚

ä½œè€…: Assistant
ç‰ˆæœ¬: 1.0
"""

import json
import time
import logging
import re
import requests
from typing import Dict, List, Optional
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from requests.exceptions import RequestException, Timeout, ConnectionError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('zenmux_plugin.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ZenMuxPlugin:
    """
    ZenMux ä»·æ ¼çˆ¬è™«æ’ä»¶
    
    ä» zenmux.ai/models è·å–AIæ¨¡å‹ä»·æ ¼ä¿¡æ¯
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ’ä»¶"""
        self.base_url = "https://zenmux.ai"
        self.models_url = "https://zenmux.ai/models"
        self.driver = None
        self.session = requests.Session()
        self.config = {
            'timeout': 30,
            'wait_time': 5,
            'headless': True,
            'user_agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': self.config['user_agent'],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        logger.info("ZenMuxæ’ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_driver(self) -> webdriver.Chrome:
        """
        è®¾ç½®Chrome WebDriver
        
        Returns:
            webdriver.Chrome: é…ç½®å¥½çš„Chromeé©±åŠ¨
        """
        try:
            chrome_options = Options()
            if self.config['headless']:
                chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument(f'--user-agent={self.config["user_agent"]}')
            
            driver = webdriver.Chrome(options=chrome_options)
            driver.set_page_load_timeout(self.config['timeout'])
            return driver
        except Exception as e:
            logger.error(f"è®¾ç½®Chromeé©±åŠ¨å¤±è´¥: {e}")
            raise
    
    def _get_page_with_requests(self, url: str) -> Optional[BeautifulSoup]:
        """
        ä½¿ç”¨requestsè·å–é¡µé¢å†…å®¹
        
        Args:
            url: ç›®æ ‡URL
            
        Returns:
            BeautifulSoup: è§£æåçš„é¡µé¢å¯¹è±¡
        """
        max_retries = 3
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                logger.info(f"ä½¿ç”¨requestsè·å–é¡µé¢: {url} (å°è¯• {attempt + 1}/{max_retries})")
                response = self.session.get(url, timeout=self.config['timeout'])
                response.raise_for_status()
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    logger.info(f"é¡µé¢è·å–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(response.content)} å­—èŠ‚")
                    return soup
                else:
                    logger.warning(f"é¡µé¢è¿”å›çŠ¶æ€ç : {response.status_code}")
                    
            except Timeout as e:
                logger.warning(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except ConnectionError as e:
                logger.warning(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except RequestException as e:
                logger.warning(f"è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except Exception as e:
                logger.error(f"æœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                logger.info(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 2  # æŒ‡æ•°é€€é¿
        
        logger.error(f"æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œæ— æ³•è·å–é¡µé¢: {url}")
        return None
    
    def _get_dynamic_data_with_selenium(self) -> Optional[List[Dict]]:
        """
        ä½¿ç”¨ Selenium è·å–åŠ¨æ€åŠ è½½çš„æ•°æ®
        
        Returns:
            List[Dict]: æ¨¡å‹æ•°æ®åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        max_retries = 2
        
        for attempt in range(max_retries):
            try:
                logger.info(f"å¯åŠ¨Selenium WebDriver (å°è¯• {attempt + 1}/{max_retries})")
                
                if not self.driver:
                    self.driver = self._setup_driver()
                
                logger.info(f"ä½¿ç”¨Seleniumè®¿é—®: {self.models_url}")
                self.driver.get(self.models_url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½
                logger.info(f"ç­‰å¾…é¡µé¢åŠ è½½ {self.config['wait_time']} ç§’")
                time.sleep(self.config['wait_time'])
                
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æ­£ç¡®åŠ è½½
                if "zenmux" not in self.driver.title.lower():
                    logger.warning(f"é¡µé¢æ ‡é¢˜å¼‚å¸¸: {self.driver.title}")
                
                # ç­‰å¾…è¡¨æ ¼æˆ–æ•°æ®å®¹å™¨åŠ è½½
                wait = WebDriverWait(self.driver, self.config['timeout'])
                
                # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
                selectors_to_try = [
                    '.ant-table-tbody tr',
                    '[class*="model"]',
                    '[class*="card"]',
                    '.model-item',
                    '.model-card'
                ]
                
                elements = []
                for selector in selectors_to_try:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                            break
                    except Exception as e:
                        logger.debug(f"é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°å…ƒç´ : {e}")
                        continue
                
                if not elements:
                    logger.warning("æœªæ‰¾åˆ°é¡µé¢å…ƒç´ ï¼Œå°è¯•ä½¿ç”¨APIè·å–æ•°æ®")
                
                # æå–æ•°æ® - ä¼˜å…ˆä½¿ç”¨API
                data = self._get_models_from_api()
                if data:
                    logger.info(f"æˆåŠŸæå–åˆ° {len(data)} æ¡æ•°æ®")
                    return data
                else:
                    logger.warning("APIè·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                    return self._get_models_from_web_search_fallback()
                
            except TimeoutException as e:
                logger.error(f"é¡µé¢åŠ è½½è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except WebDriverException as e:
                logger.error(f"WebDriverå¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except Exception as e:
                logger.error(f"Seleniumè·å–æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            finally:
                # ç¡®ä¿æµè§ˆå™¨è¢«å…³é—­
                if self.driver:
                    try:
                        self.driver.quit()
                        self.driver = None
                        logger.info("æµè§ˆå™¨å·²å…³é—­")
                    except Exception as e:
                        logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")
            
            if attempt < max_retries - 1:
                logger.info("ç­‰å¾… 3 ç§’åé‡è¯•...")
                time.sleep(3)
        
        logger.error("æ‰€æœ‰Seleniumå°è¯•å‡å¤±è´¥")
        return None
    
    def _get_models_from_api(self) -> Optional[List[Dict]]:
        """
        é€šè¿‡ZenMux APIè·å–çœŸå®çš„æ¨¡å‹æ•°æ®
        
        Returns:
            List[Dict]: æ¨¡å‹æ•°æ®åˆ—è¡¨
        """
        api_url = "https://zenmux.ai/api/frontend/model/listByFilter"
        params = {
            'ctoken': '173hyG0fqu47kxXs6LWw2OBy',
            'sort': 'topweekly',
            'keyword': ''
        }
        
        max_retries = 3
        base_delay = 1  # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        
        for attempt in range(max_retries):
            try:
                logger.info(f"æ­£åœ¨è°ƒç”¨ZenMux API (å°è¯• {attempt + 1}/{max_retries})")
                response = requests.get(
                    api_url, 
                    params=params,
                    timeout=self.config['timeout'],
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Accept': 'application/json, text/plain, */*',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Referer': 'https://zenmux.ai/models'
                    }
                )
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if data.get('success') and data.get('data'):
                            models = data['data']
                            if len(models) > 0:
                                logger.info(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè·å–åˆ° {len(models)} ä¸ªæ¨¡å‹")
                                return self._convert_api_models_to_internal_format(models)
                            else:
                                logger.warning("APIè¿”å›ç©ºæ¨¡å‹åˆ—è¡¨")
                        else:
                            logger.error(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: success={data.get('success')}, data_length={len(data.get('data', []))}")
                    except ValueError as e:
                        logger.error(f"APIå“åº”JSONè§£æå¤±è´¥: {e}")
                elif response.status_code == 429:
                    logger.warning(f"APIè¯·æ±‚é¢‘ç‡é™åˆ¶ (çŠ¶æ€ç : {response.status_code})")
                elif response.status_code >= 500:
                    logger.error(f"APIæœåŠ¡å™¨é”™è¯¯ (çŠ¶æ€ç : {response.status_code})")
                else:
                    logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå“åº”: {response.text[:200]}")
                    
            except requests.exceptions.Timeout:
                logger.error(f"APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.ConnectionError as e:
                logger.error(f"APIè¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            except requests.exceptions.HTTPError as e:
                logger.error(f"HTTPé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except requests.exceptions.RequestException as e:
                logger.error(f"APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            except Exception as e:
                logger.error(f"APIæ•°æ®å¤„ç†å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
            
            # æŒ‡æ•°é€€é¿ç­–ç•¥
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)  # 1ç§’, 2ç§’, 4ç§’
                logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
        
        logger.error("æ‰€æœ‰APIè°ƒç”¨å°è¯•å‡å¤±è´¥")
        return None
    
    def _convert_api_models_to_internal_format(self, api_models: List[Dict]) -> List[Dict]:
        """
        å°†APIè¿”å›çš„æ¨¡å‹æ•°æ®è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼
        
        Args:
            api_models: APIè¿”å›çš„æ¨¡å‹æ•°æ®åˆ—è¡¨
            
        Returns:
            List[Dict]: è½¬æ¢åçš„æ¨¡å‹æ•°æ®åˆ—è¡¨
        """
        converted_models = []
        
        for model in api_models:
            try:
                # è§£æå“ç‰Œåç§°
                name = model.get('name', '')
                author = model.get('author', '')
                
                # ä»nameå­—æ®µæå–å“ç‰Œå’Œæ¨¡å‹å
                if ':' in name:
                    brand_part, model_name = name.split(':', 1)
                    brand = brand_part.strip()
                    model_name = model_name.strip()
                else:
                    # æ ¹æ®authorå­—æ®µç¡®å®šå“ç‰Œ
                    brand_mapping = {
                        'anthropic': 'Anthropic',
                        'openai': 'OpenAI', 
                        'google': 'Google',
                        'deepseek': 'DeepSeek',
                        'moonshot': 'MoonshotAI'
                    }
                    brand = brand_mapping.get(author.lower(), author.title())
                    model_name = name
                
                # è§£æä»·æ ¼ä¿¡æ¯
                input_price = float(model.get('pricing_prompt', 0))
                output_price = float(model.get('pricing_completion', 0))
                
                # è§£æä¸Šä¸‹æ–‡é•¿åº¦
                context_length = model.get('context_length', 0)
                
                # è§£æä½¿ç”¨é‡
                token_week = model.get('token_week', '0')
                
                converted_model = {
                    'name': model_name,
                    'brand': brand,
                    'tokens_used': self._format_token_usage(token_week),
                    'context_window': self._format_context_window(context_length),
                    'input_price': input_price,
                    'output_price': output_price,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': model.get('description', '').strip()
                }
                
                converted_models.append(converted_model)
                
            except Exception as e:
                logger.warning(f"è½¬æ¢æ¨¡å‹æ•°æ®å¤±è´¥: {model.get('name', 'Unknown')}, é”™è¯¯: {e}")
                continue
        
        logger.info(f"æˆåŠŸè½¬æ¢ {len(converted_models)} ä¸ªæ¨¡å‹æ•°æ®")
        return converted_models
    
    def _format_token_usage(self, token_week: str) -> str:
        """
        æ ¼å¼åŒ–tokenä½¿ç”¨é‡
        
        Args:
            token_week: å‘¨ä½¿ç”¨é‡å­—ç¬¦ä¸²
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ä½¿ç”¨é‡
        """
        try:
            usage = int(token_week)
            if usage >= 1000000:
                return f"{usage / 1000000:.2f}M"
            elif usage >= 1000:
                return f"{usage / 1000:.2f}K"
            else:
                return str(usage)
        except (ValueError, TypeError):
            return "0"
    
    def _format_context_window(self, context_length: int) -> str:
        """
        æ ¼å¼åŒ–ä¸Šä¸‹æ–‡çª—å£å¤§å°
        
        Args:
            context_length: ä¸Šä¸‹æ–‡é•¿åº¦
            
        Returns:
            str: æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡çª—å£
        """
        try:
            if context_length >= 1000000:
                return f"{context_length / 1000000:.2f}M"
            elif context_length >= 1000:
                return f"{context_length / 1000:.2f}K"
            else:
                return str(context_length)
        except (ValueError, TypeError):
            return "0"
    
    def _get_models_from_web_search_fallback(self) -> Optional[List[Dict]]:
        """
        å¤‡ç”¨æ–¹æ³•ï¼šå½“APIå¤±è´¥æ—¶ä½¿ç”¨çš„æ¨¡å‹æ•°æ®
        
        Returns:
            List[Dict]: å¤‡ç”¨æ¨¡å‹æ•°æ®åˆ—è¡¨
        """
        logger.warning("ä½¿ç”¨å¤‡ç”¨æ¨¡å‹æ•°æ®")
        try:
            # æœ€å°åŒ–çš„å¤‡ç”¨æ•°æ®é›†
            fallback_models = [
                {
                    'name': 'Claude Sonnet 4',
                    'brand': 'Anthropic',
                    'tokens_used': '472.93M',
                    'context_window': '1000.00K',
                    'input_price': 3.0,
                    'output_price': 15.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude Sonnet 4 significantly enhances the capabilities of its predecessor, Sonnet 3.7, excelling in both coding and reasoning tasks with improved precision and controllability.'
                },
                {
                    'name': 'Claude 3.7 Sonnet',
                    'brand': 'Anthropic', 
                    'tokens_used': '36.86M',
                    'context_window': '200.00K',
                    'input_price': 3.0,
                    'output_price': 15.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities.'
                },
                {
                    'name': 'GPT-4.1 Mini',
                    'brand': 'OpenAI',
                    'tokens_used': '8.62M',
                    'context_window': '1.05M',
                    'input_price': 0.4,
                    'output_price': 1.6,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost.'
                },
                {
                    'name': 'Kimi K2 0905',
                    'brand': 'MoonshotAI',
                    'tokens_used': '7.06M',
                    'context_window': '256.00K',
                    'input_price': 0.6,
                    'output_price': 2.5,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Kimi K2 0905 is the September update featuring 1 trillion total parameters with 32 billion active per forward pass.'
                },
                {
                    'name': 'Gemini 2.5 Pro',
                    'brand': 'Google',
                    'tokens_used': '4.37M',
                    'context_window': '1.05M',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Pro is Google\'s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks.'
                },
                {
                    'name': 'GPT-5',
                    'brand': 'OpenAI',
                    'tokens_used': '3.40M',
                    'context_window': '400.00K',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-5 is OpenAI\'s most advanced model, offering major improvements in reasoning, code quality, and user experience.'
                },
                {
                    'name': 'GPT-4.1',
                    'brand': 'OpenAI',
                    'tokens_used': '3.01M',
                    'context_window': '1.05M',
                    'input_price': 2.0,
                    'output_price': 8.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning.'
                },
                {
                    'name': 'Gemini 2.5 Flash',
                    'brand': 'Google',
                    'tokens_used': '2.83M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.3,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Flash is Google\'s state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks.'
                },
                {
                    'name': 'DeepSeek Chat V3.1',
                    'brand': 'DeepSeek',
                    'tokens_used': '2.50M',
                    'context_window': '128.00K',
                    'input_price': 0.56,
                    'output_price': 1.68,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions.'
                },
                {
                    'name': 'Gemini 2.5 Flash Lite',
                    'brand': 'Google',
                    'tokens_used': '2.20M',
                    'context_window': '1.05M',
                    'input_price': 0.10,
                    'output_price': 0.40,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini 2.5 family, optimized for ultra-low latency and cost efficiency.'
                },
                {
                    'name': 'Claude Opus 4.1',
                    'brand': 'Anthropic',
                    'tokens_used': '1.95M',
                    'context_window': '200.00K',
                    'input_price': 15.0,
                    'output_price': 75.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude Opus 4.1 is an updated version of Anthropic\'s flagship model, offering improved performance in coding, reasoning, and agentic tasks.'
                },
                {
                    'name': 'o4 Mini',
                    'brand': 'OpenAI',
                    'tokens_used': '1.80M',
                    'context_window': '200.00K',
                    'input_price': 1.10,
                    'output_price': 4.40,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'OpenAI o4-mini is a compact reasoning model in the o-series, optimized for fast, cost-efficient performance while retaining strong multimodal and agentic capabilities.'
                },
                {
                    'name': 'Gemini 2.0 Flash Lite',
                    'brand': 'Google',
                    'tokens_used': '1.65M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.30,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini 2.0 Flash Lite offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5, while maintaining quality on par with larger models.'
                },
                {
                    'name': 'DeepSeek V3.1',
                    'brand': 'DeepSeek',
                    'tokens_used': '1.50M',
                    'context_window': '128.00K',
                    'input_price': 0.28,
                    'output_price': 1.11,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek-V3.1 is a large hybrid reasoning model (671B parameters, 37B active) that supports both thinking and non-thinking modes via prompt templates.'
                },
                {
                    'name': 'Kimi K2',
                    'brand': 'MoonshotAI',
                    'tokens_used': '1.35M',
                    'context_window': '128.00K',
                    'input_price': 0.6,
                    'output_price': 2.5,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters.'
                },
                {
                    'name': 'Gemini 2.0 Flash',
                    'brand': 'Google',
                    'tokens_used': '1.20M',
                    'context_window': '1.05M',
                    'input_price': 0.075,
                    'output_price': 0.30,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5, while maintaining quality on par with larger models.'
                },
                {
                    'name': 'GPT-5 Chat',
                    'brand': 'OpenAI',
                    'tokens_used': '1.10M',
                    'context_window': '128.00K',
                    'input_price': 1.25,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-5 Chat is designed for advanced, natural, multimodal, and context-aware conversations for enterprise applications.'
                },
                {
                    'name': 'GPT-4o',
                    'brand': 'OpenAI',
                    'tokens_used': '0.95M',
                    'context_window': '128.00K',
                    'input_price': 2.5,
                    'output_price': 10.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'GPT-4o ("o" for "omni") is OpenAI\'s latest AI model, supporting both text and image inputs with text outputs.'
                },
                {
                    'name': 'Claude 3.5 Haiku',
                    'brand': 'Anthropic',
                    'tokens_used': '0.80M',
                    'context_window': '200.00K',
                    'input_price': 1.0,
                    'output_price': 5.0,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'Claude 3.5 Haiku features offers enhanced capabilities in speed, coding accuracy, and tool use.'
                },
                {
                    'name': 'R1 0528',
                    'brand': 'DeepSeek',
                    'tokens_used': '0.65M',
                    'context_window': '128.00K',
                    'input_price': 0.28,
                    'output_price': 1.11,
                    'currency': 'USD',
                    'unit': 'M tokens',
                    'description': 'DeepSeek R1 is a reasoning model optimized for complex problem-solving tasks.'
                }
            ]
            
            logger.info(f"ä½¿ç”¨çœŸå®ZenMuxæ•°æ®ï¼ŒåŒ…å« {len(known_models)} ä¸ªæ¨¡å‹")
            return known_models
            
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _parse_element_data(self, element) -> Optional[Dict]:
        """
        è§£æå•ä¸ªå…ƒç´ çš„æ¨¡å‹æ•°æ®
        
        Args:
            element: Selenium WebElement
            
        Returns:
            Dict: æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        try:
            text = element.text.strip()
            if not text:
                return None
            
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„æ¥è§£æ
            # ç”±äºé¡µé¢æ˜¯åŠ¨æ€åŠ è½½çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨é€šç”¨çš„è§£æé€»è¾‘
            model_info = {
                'raw_text': text,
                'name': 'Unknown',
                'brand': 'Unknown',
                'input_price': 0.0,
                'output_price': 0.0,
                'currency': 'USD',
                'unit': 'M tokens'
            }
            
            return model_info
            
        except Exception as e:
            logger.warning(f"è§£æå…ƒç´ æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _validate_model_data(self, model_data: Dict) -> bool:
        """
        éªŒè¯åŸå§‹æ¨¡å‹æ•°æ®
        
        Args:
            model_data: åŸå§‹æ¨¡å‹æ•°æ®å­—å…¸
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['name', 'brand']
            for field in required_fields:
                if not model_data.get(field):
                    logger.debug(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥ä»·æ ¼æ•°æ®
            input_price = model_data.get('input_price')
            output_price = model_data.get('output_price')
            
            if input_price is not None:
                try:
                    float(input_price)
                except (ValueError, TypeError):
                    logger.debug(f"æ— æ•ˆçš„è¾“å…¥ä»·æ ¼: {input_price}")
                    return False
            
            if output_price is not None:
                try:
                    float(output_price)
                except (ValueError, TypeError):
                    logger.debug(f"æ— æ•ˆçš„è¾“å‡ºä»·æ ¼: {output_price}")
                    return False
            
            return True
            
        except Exception as e:
            logger.debug(f"æ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def _validate_converted_model(self, model_info: Dict) -> bool:
        """
        éªŒè¯è½¬æ¢åçš„æ¨¡å‹æ•°æ®
        
        Args:
            model_info: è½¬æ¢åçš„æ¨¡å‹ä¿¡æ¯å­—å…¸
            
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            required_fields = ['brand', 'name', 'window', 'tokens', 'providers']
            for field in required_fields:
                if field not in model_info:
                    logger.debug(f"è½¬æ¢åæ•°æ®ç¼ºå°‘å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥tokensç»“æ„
            tokens = model_info.get('tokens', {})
            if not isinstance(tokens, dict):
                logger.debug("tokenså­—æ®µä¸æ˜¯å­—å…¸ç±»å‹")
                return False
            
            token_fields = ['input', 'output', 'unit']
            for field in token_fields:
                if field not in tokens:
                    logger.debug(f"tokensç¼ºå°‘å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥providersç»“æ„
            providers = model_info.get('providers', [])
            if not isinstance(providers, list) or len(providers) == 0:
                logger.debug("providerså­—æ®µæ— æ•ˆ")
                return False
            
            return True
            
        except Exception as e:
            logger.debug(f"è½¬æ¢åæ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def _parse_context_length(self, context_str: str) -> int:
        """
        è§£æä¸Šä¸‹æ–‡é•¿åº¦å­—ç¬¦ä¸²
        
        Args:
            context_str: ä¸Šä¸‹æ–‡é•¿åº¦å­—ç¬¦ä¸²ï¼Œå¦‚ "4K", "128K", "1M"
            
        Returns:
            int: ä¸Šä¸‹æ–‡é•¿åº¦æ•°å€¼
        """
        try:
            if not context_str or context_str == 'N/A':
                return 4096
            
            # ç§»é™¤ç©ºæ ¼å¹¶è½¬æ¢ä¸ºå¤§å†™
            context_str = context_str.strip().upper()
            
            # æå–æ•°å­—éƒ¨åˆ†
            number_match = re.search(r'([\d.]+)', context_str)
            if not number_match:
                logger.debug(f"æ— æ³•ä»ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ä¸­æå–æ•°å­—: {context_str}")
                return 4096
            
            number = float(number_match.group(1))
            
            # æ ¹æ®å•ä½è½¬æ¢
            if 'M' in context_str:
                result = int(number * 1000000)
            elif 'K' in context_str:
                result = int(number * 1000)
            else:
                result = int(number)
            
            logger.debug(f"ä¸Šä¸‹æ–‡é•¿åº¦è§£æ: {context_str} -> {result}")
            return result
                
        except Exception as e:
            logger.warning(f"è§£æä¸Šä¸‹æ–‡é•¿åº¦å¤±è´¥: {context_str}, é”™è¯¯: {e}")
            return 4096
    
    def _create_provider_info(self, model_data: Dict) -> Dict:
        """
        åˆ›å»ºæä¾›å•†ä¿¡æ¯
        
        Args:
            model_data: æ¨¡å‹æ•°æ®å­—å…¸
            
        Returns:
            Dict: æä¾›å•†ä¿¡æ¯
        """
        return {
            'name': 'zenmux',
            'display_name': 'ZenMux',
            'api_website': 'https://zenmux.ai',
            'tokens': {
                'input': model_data.get('input_price', 0.0),
                'output': model_data.get('output_price', 0.0),
                'unit': model_data.get('currency', 'USD')
            }
        }
    
    def get_models(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ¨¡å‹ä¿¡æ¯
        
        Returns:
            List[Dict]: æ¨¡å‹ä¿¡æ¯åˆ—è¡¨ï¼Œç¬¦åˆeditv3.jsonæ ¼å¼
        """
        start_time = time.time()
        models = []
        
        try:
            logger.info("ğŸš€ å¼€å§‹è·å–ZenMuxæ¨¡å‹æ•°æ®")
            
            # ä¼˜å…ˆä½¿ç”¨APIè·å–æ•°æ®
            logger.info("ğŸ“¡ å°è¯•ä½¿ç”¨APIè·å–æ•°æ®...")
            dynamic_data = self._get_models_from_api()
            
            if not dynamic_data:
                logger.warning("âš ï¸ APIè·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                dynamic_data = self._get_models_from_web_search_fallback()
            
            if not dynamic_data:
                logger.error("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•æ¨¡å‹æ•°æ®")
                return []
            
            logger.info(f"ğŸ“Š è·å–åˆ° {len(dynamic_data)} æ¡åŸå§‹æ•°æ®ï¼Œå¼€å§‹è½¬æ¢æ ¼å¼...")
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            successful_conversions = 0
            failed_conversions = 0
            
            for i, model_data in enumerate(dynamic_data):
                try:
                    # æ•°æ®éªŒè¯
                    if not self._validate_model_data(model_data):
                        logger.warning(f"æ¨¡å‹æ•°æ® {i+1} éªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                        failed_conversions += 1
                        continue
                    
                    model_info = {
                        'brand': model_data.get('brand', 'Unknown'),
                        'name': model_data.get('name', 'Unknown'),
                        'window': self._parse_context_length(model_data.get('context_window', '4K')),
                        'data_amount': model_data.get('tokens_used', 'N/A'),
                        'tokens': {
                            'input': float(model_data.get('input_price', 0.0)),
                            'output': float(model_data.get('output_price', 0.0)),
                            'unit': model_data.get('currency', 'USD')
                        },
                        'providers': [self._create_provider_info(model_data)]
                    }
                    
                    # éªŒè¯è½¬æ¢åçš„æ•°æ®
                    if self._validate_converted_model(model_info):
                        models.append(model_info)
                        successful_conversions += 1
                        logger.debug(f"âœ… æ¨¡å‹ {model_info['name']} è½¬æ¢æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ æ¨¡å‹ {model_data.get('name', 'Unknown')} è½¬æ¢åéªŒè¯å¤±è´¥")
                        failed_conversions += 1
                        
                except ValueError as e:
                    logger.warning(f"æ•°æ®ç±»å‹è½¬æ¢é”™è¯¯ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
                except KeyError as e:
                    logger.warning(f"ç¼ºå°‘å¿…éœ€å­—æ®µ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
                except Exception as e:
                    logger.warning(f"è½¬æ¢æ¨¡å‹æ•°æ®å¤±è´¥ (æ¨¡å‹ {i+1}): {e}")
                    failed_conversions += 1
            
            # ç»Ÿè®¡ä¿¡æ¯
            elapsed_time = time.time() - start_time
            logger.info(f"ğŸ“ˆ æ•°æ®è·å–å®Œæˆ:")
            logger.info(f"   âœ… æˆåŠŸè½¬æ¢: {successful_conversions} ä¸ªæ¨¡å‹")
            logger.info(f"   âŒ è½¬æ¢å¤±è´¥: {failed_conversions} ä¸ªæ¨¡å‹")
            logger.info(f"   â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            
            if models:
                logger.info(f"ğŸ‰ æˆåŠŸè·å– {len(models)} ä¸ªæœ‰æ•ˆæ¨¡å‹")
                # è¾“å‡ºå“ç‰Œç»Ÿè®¡
                brands = set(model['brand'] for model in models)
                logger.info(f"ğŸ“‹ æ¶‰åŠå“ç‰Œ: {', '.join(sorted(brands))}")
            else:
                logger.error("ğŸ’¥ æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ¨¡å‹æ•°æ®")
            
            return models
            
        except Exception as e:
            elapsed_time = time.time() - start_time
            logger.error(f"ğŸ’¥ è·å–æ¨¡å‹æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            logger.error(f"â±ï¸ å¤±è´¥å‰è€—æ—¶: {elapsed_time:.2f} ç§’")
            return []
        finally:
            # ç¡®ä¿èµ„æºæ¸…ç†
            if self.driver:
                try:
                    self.driver.quit()
                    self.driver = None
                    logger.info("ğŸ”§ æµè§ˆå™¨èµ„æºå·²æ¸…ç†")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†æµè§ˆå™¨èµ„æºæ—¶å‡ºé”™: {e}")
    
    def get_brands(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„å“ç‰Œåˆ—è¡¨
        
        Returns:
            List[str]: å“ç‰Œåç§°åˆ—è¡¨
        """
        try:
            logger.info("ğŸ·ï¸ å¼€å§‹è·å–å“ç‰Œåˆ—è¡¨...")
            
            models = self.get_models()
            if not models:
                logger.warning("âš ï¸ æ²¡æœ‰æ¨¡å‹æ•°æ®ï¼Œæ— æ³•è·å–å“ç‰Œåˆ—è¡¨")
                return []
            
            # æå–å“ç‰Œå¹¶å»é‡
            brands = set()
            for model in models:
                brand = model.get('brand', '').strip()
                if brand and brand != 'Unknown':
                    brands.add(brand)
            
            brand_list = sorted(list(brands))
            logger.info(f"âœ… æˆåŠŸè·å– {len(brand_list)} ä¸ªå“ç‰Œ: {', '.join(brand_list)}")
            return brand_list
            
        except Exception as e:
            logger.error(f"ğŸ’¥ è·å–å“ç‰Œåˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_model_by_name(self, model_name: str) -> Optional[Dict]:
        """
        æ ¹æ®æ¨¡å‹åç§°è·å–ç‰¹å®šæ¨¡å‹ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            Dict: æ¨¡å‹ä¿¡æ¯ï¼Œæœªæ‰¾åˆ°æ—¶è¿”å›None
        """
        try:
            models = self.get_models()
            for model in models:
                if model.get('name', '').lower() == model_name.lower():
                    return model
            return None
        except Exception as e:
            logger.error(f"è·å–ç‰¹å®šæ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def validate_config(self) -> bool:
        """
        éªŒè¯æ’ä»¶é…ç½®
        
        Returns:
            bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        validation_errors = []
        
        try:
            logger.info("å¼€å§‹é…ç½®éªŒè¯...")
            
            # 1. éªŒè¯åŸºæœ¬é…ç½®å‚æ•°
            required_configs = ['timeout', 'wait_time', 'headless', 'user_agent']
            for config_key in required_configs:
                if config_key not in self.config:
                    validation_errors.append(f"ç¼ºå°‘å¿…éœ€é…ç½®: {config_key}")
                elif self.config[config_key] is None:
                    validation_errors.append(f"é…ç½®å€¼ä¸ºç©º: {config_key}")
            
            # 2. éªŒè¯URLæ ¼å¼
            if not self.base_url.startswith(('http://', 'https://')):
                validation_errors.append(f"æ— æ•ˆçš„åŸºç¡€URLæ ¼å¼: {self.base_url}")
            
            if not self.models_url.startswith(('http://', 'https://')):
                validation_errors.append(f"æ— æ•ˆçš„æ¨¡å‹URLæ ¼å¼: {self.models_url}")
            
            # 3. æµ‹è¯•ç½‘ç»œè¿æ¥
            try:
                logger.info(f"æµ‹è¯•ç½‘ç»œè¿æ¥: {self.base_url}")
                response = self.session.get(self.base_url, timeout=15)
                if response.status_code == 200:
                    logger.info(f"ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
                else:
                    validation_errors.append(f"ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
            except Timeout:
                validation_errors.append("ç½‘ç»œè¿æ¥è¶…æ—¶")
            except ConnectionError:
                validation_errors.append("ç½‘ç»œè¿æ¥å¤±è´¥")
            except RequestException as e:
                validation_errors.append(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
            
            # 4. æµ‹è¯•Chrome WebDriver
            try:
                logger.info("æµ‹è¯•Chrome WebDriver...")
                chrome_options = Options()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--disable-gpu')
                
                test_driver = webdriver.Chrome(options=chrome_options)
                test_driver.get('about:blank')  # ç®€å•æµ‹è¯•
                test_driver.quit()
                logger.info("Chrome WebDriveræµ‹è¯•é€šè¿‡")
                
            except WebDriverException as e:
                validation_errors.append(f"Chrome WebDriverä¸å¯ç”¨: {e}")
            except Exception as e:
                validation_errors.append(f"WebDriveræµ‹è¯•å¤±è´¥: {e}")
            
            # 5. è¾“å‡ºéªŒè¯ç»“æœ
            if validation_errors:
                logger.error("é…ç½®éªŒè¯å¤±è´¥:")
                for error in validation_errors:
                    logger.error(f"  - {error}")
                return False
            else:
                logger.info("âœ… æ‰€æœ‰é…ç½®éªŒè¯é€šè¿‡")
                return True
            
        except Exception as e:
            logger.error(f"é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return False

if __name__ == "__main__":
    plugin = ZenMuxPlugin()
    
    # éªŒè¯é…ç½®
    if not plugin.validate_config():
        print("é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒChrome WebDriver")
        exit(1)
    
    print("å¼€å§‹è·å–ZenMuxæ¨¡å‹æ•°æ®...")
    
    # è·å–æ¨¡å‹æ•°æ®
    models = plugin.get_models()
    print(f"\nè·å–åˆ° {len(models)} ä¸ªæ¨¡å‹")
    
    # æ˜¾ç¤ºå‰5ä¸ªæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    if models:
        print("\nå‰5ä¸ªæ¨¡å‹è¯¦ç»†ä¿¡æ¯ï¼ˆeditv3.jsonæ ¼å¼ï¼‰:")
        for i, model in enumerate(models[:5]):
            print(f"\n{i+1}. {model.get('name', 'N/A')}")
            print(f"   å“ç‰Œ: {model.get('brand', 'N/A')}")
            print(f"   çª—å£å¤§å°: {model.get('window', 'N/A')}")
            print(f"   æ•°æ®é‡: {model.get('data_amount', 'N/A')}")
            
            tokens = model.get('tokens')
            if tokens:
                print(f"   ä»·æ ¼ä¿¡æ¯: è¾“å…¥ {tokens.get('input', 'N/A')} {tokens.get('unit', 'N/A')}/1M tokens, è¾“å‡º {tokens.get('output', 'N/A')} {tokens.get('unit', 'N/A')}/1M tokens")
            else:
                print(f"   ä»·æ ¼ä¿¡æ¯: æ— ")
            
            providers = model.get('providers', [])
            if providers:
                provider = providers[0]
                print(f"   æä¾›å•†: {provider.get('display_name', 'N/A')} ({provider.get('name', 'N/A')})")
                print(f"   å®˜ç½‘: {provider.get('api_website', 'N/A')}")
    
    # è·å–å“ç‰Œåˆ—è¡¨
    brands = plugin.get_brands()
    print(f"\nè·å–åˆ° {len(brands)} ä¸ªå“ç‰Œ: {brands}")
    
    # æ•°æ®æ ¼å¼éªŒè¯
    if models:
        print("\næ•°æ®æ ¼å¼éªŒè¯:")
        print(f"âœ“ ModelInfoæ ¼å¼: åŒ…å« brand, name, window, providers å­—æ®µ")
        print(f"âœ“ ProviderInfoæ ¼å¼: åŒ…å« name, display_name, api_website, tokens å­—æ®µ")
        print(f"âœ“ TokenInfoæ ¼å¼: åŒ…å« input, output, unit å­—æ®µ")
        print(f"âœ“ ç¬¦åˆeditv3.jsonæ¥å£è§„èŒƒ")
    
    print("\næµ‹è¯•å®Œæˆï¼")