#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†ææµ‹è¯•è„šæœ¬

åˆ†æä» AIHubMix API è·å–çš„æ¨¡å‹æ•°æ®ï¼Œå±•ç¤ºè¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
"""

import json
import logging
import requests
from collections import Counter, defaultdict
from typing import Dict, List, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fetch_api_data() -> Optional[List[Dict]]:
    """
    ä» API è·å–æ¨¡å‹æ•°æ®
    
    Returns:
        Optional[List[Dict]]: æ¨¡å‹æ•°æ®åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    api_url = "https://aihubmix.com/call/mdl_info"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/plain, */*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'https://aihubmix.com/models',
        'Origin': 'https://aihubmix.com'
    }
    
    try:
        logger.info(f"æ­£åœ¨è¯·æ±‚ API: {api_url}")
        response = requests.get(api_url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            logger.error(f"API è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None
        
        data = response.json()
        if not data.get('success', False):
            logger.error("API è¿”å›å¤±è´¥çŠ¶æ€")
            return None
        
        models_data = data.get('data', [])
        logger.info(f"æˆåŠŸä» API è·å–åˆ° {len(models_data)} ä¸ªæ¨¡å‹æ•°æ®")
        return models_data
        
    except Exception as e:
        logger.error(f"è·å– API æ•°æ®å¤±è´¥: {e}")
        return None

def analyze_data_structure(models_data: List[Dict]) -> None:
    """
    åˆ†ææ•°æ®ç»“æ„
    
    Args:
        models_data: æ¨¡å‹æ•°æ®åˆ—è¡¨
    """
    print("\n=== æ•°æ®ç»“æ„åˆ†æ ===")
    
    if not models_data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return
    
    # åˆ†æç¬¬ä¸€ä¸ªæ¨¡å‹çš„å­—æ®µç»“æ„
    sample_model = models_data[0]
    print(f"ğŸ“Š æ•°æ®å­—æ®µç»“æ„ï¼ˆåŸºäºç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰:")
    for key, value in sample_model.items():
        value_type = type(value).__name__
        value_preview = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
        print(f"  â€¢ {key}: {value_type} = {value_preview}")
    
    # ç»Ÿè®¡æ‰€æœ‰å­—æ®µå‡ºç°é¢‘ç‡
    all_fields = Counter()
    for model in models_data:
        all_fields.update(model.keys())
    
    print(f"\nğŸ“ˆ å­—æ®µå‡ºç°é¢‘ç‡ç»Ÿè®¡:")
    for field, count in all_fields.most_common():
        percentage = (count / len(models_data)) * 100
        print(f"  â€¢ {field}: {count}/{len(models_data)} ({percentage:.1f}%)")

def analyze_brands_and_models(models_data: List[Dict]) -> None:
    """
    åˆ†æå“ç‰Œå’Œæ¨¡å‹åˆ†å¸ƒ
    
    Args:
        models_data: æ¨¡å‹æ•°æ®åˆ—è¡¨
    """
    print("\n=== å“ç‰Œå’Œæ¨¡å‹åˆ†æ ===")
    
    # ç»Ÿè®¡å“ç‰Œåˆ†å¸ƒ
    brand_counter = Counter()
    model_names = []
    
    for model in models_data:
        developer = model.get('developer', 'Unknown')
        model_name = model.get('model', '') or model.get('model_name', '')
        
        brand_counter[developer] += 1
        if model_name:
            model_names.append(model_name)
    
    print(f"ğŸ¢ å“ç‰Œåˆ†å¸ƒï¼ˆå‰10åï¼‰:")
    for brand, count in brand_counter.most_common(10):
        percentage = (count / len(models_data)) * 100
        print(f"  â€¢ {brand}: {count} ä¸ªæ¨¡å‹ ({percentage:.1f}%)")
    
    print(f"\nğŸ“ æ¨¡å‹åç§°ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
    for i, name in enumerate(model_names[:10], 1):
        print(f"  {i}. {name}")
    
    print(f"\nğŸ“Š æ€»è®¡: {len(brand_counter)} ä¸ªå“ç‰Œ, {len(model_names)} ä¸ªæ¨¡å‹")

def analyze_pricing_data(models_data: List[Dict]) -> None:
    """
    åˆ†æä»·æ ¼æ•°æ®
    
    Args:
        models_data: æ¨¡å‹æ•°æ®åˆ—è¡¨
    """
    print("\n=== ä»·æ ¼æ•°æ®åˆ†æ ===")
    
    ratios = []
    completion_ratios = []
    
    for model in models_data:
        model_ratio = model.get('model_ratio', 0)
        completion_ratio = model.get('completion_ratio', 0)
        
        if model_ratio and model_ratio > 0:
            ratios.append(float(model_ratio))
        
        if completion_ratio and completion_ratio > 0:
            completion_ratios.append(float(completion_ratio))
    
    if ratios:
        print(f"ğŸ’° æ¨¡å‹ä»·æ ¼æ¯”ä¾‹ç»Ÿè®¡:")
        print(f"  â€¢ æœ‰ä»·æ ¼æ•°æ®çš„æ¨¡å‹: {len(ratios)}/{len(models_data)} ({len(ratios)/len(models_data)*100:.1f}%)")
        print(f"  â€¢ æœ€ä½ä»·æ ¼æ¯”ä¾‹: {min(ratios):.6f}")
        print(f"  â€¢ æœ€é«˜ä»·æ ¼æ¯”ä¾‹: {max(ratios):.6f}")
        print(f"  â€¢ å¹³å‡ä»·æ ¼æ¯”ä¾‹: {sum(ratios)/len(ratios):.6f}")
        
        # ä»·æ ¼åŒºé—´åˆ†å¸ƒ
        price_ranges = {
            'è¶…ä½ä»· (â‰¤0.001)': len([r for r in ratios if r <= 0.001]),
            'ä½ä»· (0.001-0.01)': len([r for r in ratios if 0.001 < r <= 0.01]),
            'ä¸­ä»· (0.01-0.1)': len([r for r in ratios if 0.01 < r <= 0.1]),
            'é«˜ä»· (>0.1)': len([r for r in ratios if r > 0.1])
        }
        
        print(f"\nğŸ“Š ä»·æ ¼åŒºé—´åˆ†å¸ƒ:")
        for range_name, count in price_ranges.items():
            if count > 0:
                percentage = (count / len(ratios)) * 100
                print(f"  â€¢ {range_name}: {count} ä¸ªæ¨¡å‹ ({percentage:.1f}%)")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä»·æ ¼æ•°æ®")

def analyze_descriptions(models_data: List[Dict]) -> None:
    """
    åˆ†ææ¨¡å‹æè¿°ä¿¡æ¯
    
    Args:
        models_data: æ¨¡å‹æ•°æ®åˆ—è¡¨
    """
    print("\n=== æè¿°ä¿¡æ¯åˆ†æ ===")
    
    descriptions = []
    context_info = []
    
    for model in models_data:
        desc = model.get('desc', '')
        if desc:
            descriptions.append(desc)
            
            # æå–ä¸Šä¸‹æ–‡é•¿åº¦ä¿¡æ¯
            import re
            context_match = re.search(r'([0-9]+[KMB]?)\s*(?:ä»¤ç‰Œ|token|ä¸Šä¸‹æ–‡|context)', desc, re.IGNORECASE)
            if context_match:
                context_info.append(context_match.group(1))
    
    print(f"ğŸ“ æè¿°ä¿¡æ¯ç»Ÿè®¡:")
    print(f"  â€¢ æœ‰æè¿°çš„æ¨¡å‹: {len(descriptions)}/{len(models_data)} ({len(descriptions)/len(models_data)*100:.1f}%)")
    
    if descriptions:
        avg_length = sum(len(desc) for desc in descriptions) / len(descriptions)
        print(f"  â€¢ å¹³å‡æè¿°é•¿åº¦: {avg_length:.0f} å­—ç¬¦")
        
        # æ˜¾ç¤ºå‡ ä¸ªæè¿°ç¤ºä¾‹
        print(f"\nğŸ“„ æè¿°ç¤ºä¾‹:")
        for i, desc in enumerate(descriptions[:3], 1):
            preview = desc[:100] + "..." if len(desc) > 100 else desc
            print(f"  {i}. {preview}")
    
    if context_info:
        print(f"\nğŸ” ä¸Šä¸‹æ–‡é•¿åº¦ä¿¡æ¯:")
        context_counter = Counter(context_info)
        for context, count in context_counter.most_common(5):
            print(f"  â€¢ {context}: {count} ä¸ªæ¨¡å‹")

def save_sample_data(models_data: List[Dict]) -> None:
    """
    ä¿å­˜æ ·æœ¬æ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        models_data: æ¨¡å‹æ•°æ®åˆ—è¡¨
    """
    print("\n=== ä¿å­˜æ ·æœ¬æ•°æ® ===")
    
    # ä¿å­˜å‰5ä¸ªæ¨¡å‹çš„å®Œæ•´æ•°æ®
    sample_data = models_data[:5]
    
    try:
        with open('sample_models.json', 'w', encoding='utf-8') as f:
            json.dump(sample_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²ä¿å­˜å‰5ä¸ªæ¨¡å‹çš„æ ·æœ¬æ•°æ®åˆ° sample_models.json")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ ·æœ¬æ•°æ®å¤±è´¥: {e}")

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®åˆ†æ
    """
    print("ğŸš€ å¼€å§‹ AIHubMix æ•°æ®åˆ†ææµ‹è¯•")
    print("=" * 50)
    
    # è·å–æ•°æ®
    models_data = fetch_api_data()
    if not models_data:
        print("âŒ æ— æ³•è·å–æ•°æ®ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    print(f"âœ… æˆåŠŸè·å– {len(models_data)} ä¸ªæ¨¡å‹æ•°æ®")
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    analyze_data_structure(models_data)
    analyze_brands_and_models(models_data)
    analyze_pricing_data(models_data)
    analyze_descriptions(models_data)
    save_sample_data(models_data)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ•°æ®åˆ†ææµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()